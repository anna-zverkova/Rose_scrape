{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import urllib.request\n",
    "from urllib.request import urlretrieve, Request, urlopen\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### URL structure\n",
    "\n",
    "URL starting page:\n",
    "\n",
    "Starting page - https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=0&qc=0\n",
    "\n",
    "Second page - https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=1&qc=0\n",
    "\n",
    "Third page - https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=2&qc=0\n",
    "\n",
    "To navigate to the next page you will need to increase by one in the initial url \"qn=\".\n",
    "\n",
    "Base of the url for rose pages:\n",
    "\n",
    "https://www.helpmefind.com/rose/\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* 'grp' is the first latter of the rose name. grp=A will bring names that start with 'A'.\n",
    "\n",
    "* 't' determins wich search tab we use on the website. In our case we are interested in tab two, which is alphabetic lists. \n",
    "\n",
    "* 'gn' determins page per letter specified by parameter 'grp'.\n",
    "\n",
    "* 'qc' does not make a difference in our case. Will be left as default zero.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=0&qc=0\n",
      "['/css/minX/hmf.e963512e2160d6eb8f2f470607749660.minX.css', '/css/minX/cluetip.7432ee7f44458f58ee235146b03718d3.minX.css', '/css/minX/jquery-ui.5c7a0b384ab167ab29b0064c4346fef8.minX.css', '/css/minX/jquery-ui-overide.1512a14de489f2215b7525048f7b5fd6.minX.css', 'guest.php', '/gardening/donations.php', '/gardening/miscFrm.php?f=40', '/gardening/qcsFrm.php?qcCategoryID=33&qcTopicID=179&qcTyp=3', '/gardening/qcsFrm.php?qcCategoryID=33&qcTopicID=200&qcTyp=3', 'https://www.helpmefind.com/rose/index.php', 'https://www.helpmefind.com/gardening/membership.php', 'https://www.helpmefind.com/gardening/sponsorship.php', 'https://www.helpmefind.com/gardening/donations.php', 'https://www.helpmefind.com/gardening/recent.php', 'https://www.helpmefind.com/rose/plants.php', 'https://www.helpmefind.com/rose/plants.php?tab=5', 'https://www.helpmefind.com/rose/cuttings.php', 'https://www.helpmefind.com/rose/plants.php?tab=15', 'https://www.helpmefind.com/rose/nurseries.php', 'https://www.helpmefind.com/rose/products.php', 'https://www.helpmefind.com/rose/gardens.php', 'https://www.helpmefind.com/rose/societies.php', 'https://www.helpmefind.com/rose/awards.php', 'https://www.helpmefind.com/gardening/ezine.php', 'https://www.helpmefind.com/gardening/qcs.php?tab=1', 'https://www.helpmefind.com/rose/publications.php', 'https://www.helpmefind.com/gardening/glossary.php', 'https://www.helpmefind.com/rose/links.php', 'https://www.helpmefind.com/gardening/calendar.php', 'https://www.helpmefind.com/gardening/members.php', 'https://www.helpmefind.com/rose/breeders.php', 'https://www.helpmefind.com/rose/authors.php', 'https://www.helpmefind.com/rose/favorites.php', 'https://www.helpmefind.com/rose/ratings.php', '/rose/plants.php?tab=1', '/rose/plants.php?tab=2', '/rose/plants.php?tab=5', '/rose/plants.php?tab=6', '/rose/plants.php?tab=36', '/rose/plants.php?tab=34', '/rose/plants.php?tab=43', '/gardening/message.php?n=2302', '/rose/plants.php?grp=A&t=2&qn=1&qc=0', '/rose/l.php?l=2.65689', '/rose/l.php?l=2.35077.7', '/rose/l.php?l=2.58955', '/rose/l.php?l=2.69785', '/rose/l.php?l=2.35206', '/rose/l.php?l=2.35206.1', '/rose/l.php?l=2.35077.2', '/rose/l.php?l=2.35198.4', '/rose/l.php?l=2.28963.2', '/rose/l.php?l=2.28138.3', '/rose/l.php?l=2.75668.2', '/rose/l.php?l=2.62121.1', '/rose/l.php?l=2.35198', '/rose/l.php?l=2.72819.4', '/rose/l.php?l=2.61483', '/rose/l.php?l=2.38344', '/rose/l.php?l=2.6738', '/rose/l.php?l=2.70948', '/rose/l.php?l=2.2768.3', '/rose/l.php?l=2.33911', '/rose/l.php?l=2.21172', '/rose/l.php?l=2.74122', '/rose/l.php?l=2.6756', '/rose/l.php?l=2.31231', '/rose/l.php?l=2.35078.1', '/rose/l.php?l=2.25367', '/rose/l.php?l=2.6776', '/rose/l.php?l=2.33686', '/rose/l.php?l=2.35194', '/rose/l.php?l=2.35203', '/rose/l.php?l=2.33687.1', '/rose/l.php?l=2.58361', '/rose/l.php?l=2.82076', '/rose/l.php?l=2.18854', '/rose/l.php?l=2.59405.3', '/rose/l.php?l=2.35194.1', '/rose/l.php?l=2.45211.1', '/rose/l.php?l=2.870.4', '/rose/l.php?l=2.24523', '/rose/l.php?l=2.73494', '/rose/l.php?l=2.59265.1', '/rose/l.php?l=2.69821', '/rose/l.php?l=2.33687', '/rose/l.php?l=2.59282.1', '/rose/l.php?l=2.76584', '/rose/l.php?l=2.82077', '/rose/l.php?l=2.35193', '/rose/l.php?l=2.73283.1', '/rose/l.php?l=2.73075', '/rose/l.php?l=2.46022', '/rose/plants.php?grp=A&t=2&qn=1&qc=0']\n"
     ]
    }
   ],
   "source": [
    "# getting all urls from the page\n",
    "# quick review\n",
    "\n",
    "for i in range(0,1):\n",
    "    url = \"https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=\" + str(i) + \"&qc=0\"\n",
    "    print(url)\n",
    "    urllist = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", urllib.request.urlopen(url).read().decode(\"utf-8\"))\n",
    "    print(urllist)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adding to the list index urls that point to specific rose pages\n",
    "\n",
    "list_of_rose_indexes_a = []\n",
    "for i in range(0,67):\n",
    "    url = \"https://www.helpmefind.com/rose/plants.php?grp=A&t=2&qn=\" + str(i) + \"&qc=0\"\n",
    "    urllist = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", urllib.request.urlopen(url).read().decode(\"utf-8\"))\n",
    "    for file_link in urllist:\n",
    "        if fnmatch.fnmatch(file_link, '/rose/l.php?l*'):\n",
    "            # print(file_link)\n",
    "            list_of_rose_indexes_a.append(file_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3323"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many links got identified in the stage above\n",
    "len(list_of_rose_indexes_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/rose/l.php?l=2.65689',\n",
       " '/rose/l.php?l=2.35077.7',\n",
       " '/rose/l.php?l=2.58955',\n",
       " '/rose/l.php?l=2.69785',\n",
       " '/rose/l.php?l=2.35206']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listing 5 first urls in the list \"list_of_pages_to_scrape_a\"\n",
    "list_of_rose_indexes_a[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of proper rose urls\n",
    "\n",
    "list_of_pages_to_scrape = []\n",
    "base_link = 'https://www.helpmefind.com'\n",
    "for url in list_of_rose_indexes_a:\n",
    "    rose_url = base_link + url\n",
    "    list_of_pages_to_scrape.append(rose_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3323"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_pages_to_scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all rose urls for rose names that start with letter 'A'. \n",
    "\n",
    "Next challenge is to identify structure of rose pages and scrape data from them in the csv file. \n",
    "\n",
    "We will be scraping data from the html file since this is the only format that the website provides. Looks like it is time to use BeautifulSoup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv\n",
    "\n",
    "filename = \"Helpmefind_roses_a.csv\"\n",
    "\n",
    "\n",
    "with open(filename,'w',newline='',encoding='utf-8') as f:\n",
    "    w = csv.writer(f)\n",
    "    headers = 'Rose_name URL Synonyms ARS Origin Class Bloom Habit Growing Parentage Notes'\n",
    "    bytes_headers = bytes(headers, 'utf-8')\n",
    "    w.writerow(headers.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list_roses = list_of_pages_to_scrape[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rose_link in text_list_roses:\n",
    "    \n",
    "    source = requests.get(rose_link).text\n",
    "\n",
    "    # Parsing in BeautifulSoup\n",
    "\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "   # rose = soup.find(\"td\", {\"class\":\"content\"})\n",
    "\n",
    "   # print(rose.prettify())\n",
    "    \n",
    "   # rose_div = rose.find_all(\"div\", class_=\"hdg\")\n",
    "    \n",
    "   # print(rose_div)\n",
    "\n",
    "    rose_title = rose.find_all(\"span\", style=\"font-variant:small-caps;\")\n",
    "    #title = rose_title.text\n",
    "    print(rose_title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    origin = soup.select_one('div.hdg:contains(\"Origin:\") + .grp')\n",
    "    if origin is not None:\n",
    "        origin_ = origin.text\n",
    "    else:\n",
    "        origin_ = \"\"\n",
    "    print(origin_)\n",
    "    \n",
    "    \n",
    "    synonyms = soup.select_one('div.hdg:contains(\"Synonyms:\") + .grp')\n",
    "    if synonyms is not None:\n",
    "        synonym = synonyms.text\n",
    "    else:\n",
    "        synonym = \"\"\n",
    "    print(synonym)\n",
    "    \n",
    "    \n",
    "    ars = soup.select_one('div.hdg:contains(\"ARS:\") + .grp')\n",
    "    if ars is not None:\n",
    "        ars_ = ars.text\n",
    "    else:\n",
    "        ars_ = \"\"\n",
    "    print(ars_)\n",
    "    \n",
    "    \n",
    "    classs = soup.select_one('div.hdg:contains(\"Class:\") + .grp')\n",
    "    if classs is not None:\n",
    "        class_ = classs.text\n",
    "    else:\n",
    "        class_ = \"\"\n",
    "    print(class_)\n",
    "    \n",
    "    \n",
    "    growing = soup.select_one('div.hdg:contains(\"Growing:\") + .grp')\n",
    "    if growing is not None:\n",
    "        growing_ = growing.text\n",
    "    else:\n",
    "        growing_ = \"\"\n",
    "    print(growing_)\n",
    "    \n",
    "    \n",
    "    habit = soup.select_one('div.hdg:contains(\"Habit:\") + .grp')\n",
    "    if habit is not None:\n",
    "        habit_ = habit.text\n",
    "    else:\n",
    "        habit_ = \"\"\n",
    "    print(habit_)\n",
    "    \n",
    "\n",
    "    parentage = soup.select_one('div.hdg:contains(\"Parentage:\") + .grp')\n",
    "    if parentage is not None:\n",
    "        parentage_ = parentage.text\n",
    "    else:\n",
    "        parentage_ = \"\"\n",
    "    print(parentage_)\n",
    "    \n",
    "    \n",
    "    notes = soup.select_one('div.hdg:contains(\"Notes:\") + .grp')\n",
    "    if notes is not None:\n",
    "        notes_ = notes.text\n",
    "    else:\n",
    "        notes_ = \"\"\n",
    "    print(notes_)\n",
    "    \n",
    "\n",
    "    bloom = soup.select_one('div.hdg:contains(\"Bloom:\") + .grp')\n",
    "    if bloom is not None:\n",
    "        bloom_ = bloom.text\n",
    "    else:\n",
    "        bloom_ = \"\"\n",
    "    print(bloom_)\n",
    "\n",
    "#    bloom = soup.select_one('div.hdg:contains(\"Bloom:\") + .grp').text\n",
    "    \n",
    "  #  print(origin)\n",
    "  #  print(ars)\n",
    "  #  print(class_)\n",
    "  #  print(growing)\n",
    "  #  print(habit)\n",
    "  #  print(parentage)\n",
    "  #  print(notes)\n",
    "  #  print(bloom)\n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting extra data from scraped url and adding it to dictionary\n",
    "\n",
    "    results = {}\n",
    "    for item in rose2.find_all(class_='characteristics-wrapper')[0].find_all(\"li\"):\n",
    "        try:\n",
    "            characteristic = item.h4.text\n",
    "        except Exception as e:\n",
    "            characteristic = 'None'\n",
    "        try:\n",
    "            type = item.p.text\n",
    "        except Exception as e:\n",
    "            type = 'None'\n",
    "        results[characteristic] = type\n",
    "        print('Characteristic : {}'.format(characteristic), 'Type : {}'.format(type))\n",
    "        print(results)\n",
    "\n",
    "# Printing data to csv file\n",
    "# Had to change encoding of name as it was not in utf-8\n",
    "    family = results.get('Family:')\n",
    "    print(family)\n",
    "    fragrance = results.get('Fragrance Strength:')\n",
    "    print(fragrance)\n",
    "    flowering = results.get('Flowering:')\n",
    "    print(flowering)\n",
    "    notes = results.get('Fragrance Notes:')\n",
    "    print(notes)\n",
    "    color2 = results.get('Colour:')\n",
    "    print(color2)\n",
    "    height = results.get('Height:')\n",
    "    print(height)\n",
    "\n",
    "    w.writerow([(name.encode('ascii','ignore')).decode('utf-8'),url,category,(price.encode('ascii','ignore')).decode('utf-8'),color,family,fragrance,flowering,notes,color2,height])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
